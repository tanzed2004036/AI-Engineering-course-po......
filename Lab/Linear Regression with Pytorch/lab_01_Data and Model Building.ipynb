{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Data & Model Building\n",
    "\n",
    "In this notebook, we'll create synthetic linear data, split it into training and test sets, visualize it, and build our first PyTorch model.\n",
    "\n",
    "Our goal: Build a model that can learn the pattern of a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "First, let's install the required libraries by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "We need:\n",
    "- `torch`: Core PyTorch library for tensors\n",
    "- `torch.nn`: Contains building blocks for neural networks\n",
    "- `matplotlib`: For visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating Synthetic Data\n",
    "\n",
    "We'll create data using the linear regression formula: `y = weight * X + bias`\n",
    "\n",
    "We set **known parameters** that our model will try to learn:\n",
    "- `weight = 0.4` (the slope)\n",
    "- `bias = 0.1` (the y-intercept)\n",
    "\n",
    "We create 50 evenly spaced X values between 0 and 1, then compute the corresponding y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.4\n",
    "bias = 0.1\n",
    "\n",
    "# Create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "X[:10], y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to build a model that can learn the relationship between `X` (features) and `y` (labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why unsqueeze?\n",
    "\n",
    "The `unsqueeze(dim=1)` adds an extra dimension to X, changing it from shape `[50]` to `[50, 1]`. PyTorch models expect input data in the format `[batch_size, features]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Number of samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting Data into Train and Test Sets\n",
    "\n",
    "One of the most important steps in a machine learning project is creating a training and test set.\n",
    "\n",
    "![Train Test Split](https://raw.githubusercontent.com/poridhiEng/lab-asset/7008e578e0c9c57813d1b267134700911793d762/tensorcode/Deep-learning-with-pytorch/LinearRegression/lab-01/images/train-test-split.svg)\n",
    "\n",
    "- **Training set**: The model learns from this data (~80%)\n",
    "- **Test set**: The model gets evaluated on this data (~20%)\n",
    "\n",
    "We want our model to learn from training data and then evaluate it on test data to see how well it **generalizes** to unseen examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "train_split = int(0.8 * len(X))  # 80% for training, 20% for testing\n",
    "\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_test, y_test = X[train_split:], y[train_split:]\n",
    "\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got 40 samples for training and 10 samples for testing.\n",
    "\n",
    "The model will try to learn the relationship between `X_train` & `y_train`, then we'll evaluate what it learned on `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Data\n",
    "\n",
    "Right now our data is just numbers on a page. Let's create a function to visualize it.\n",
    "\n",
    "The `plot_predictions()` function creates a scatter plot showing training data (blue), test data (red), and optionally model predictions (green). This helps us visually compare how well our model's predictions match the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train, \n",
    "                     train_labels=y_train, \n",
    "                     test_data=X_test, \n",
    "                     test_labels=y_test, \n",
    "                     predictions=None):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "    \n",
    "    # Plot test data in red\n",
    "    plt.scatter(test_data, test_labels, c=\"r\", s=4, label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions in green (predictions were made on the test data)\n",
    "        plt.scatter(test_data, predictions, c=\"g\", s=4, label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={\"size\": 14})\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize our data. We should see a straight line pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of just numbers on a page, our data is a straight line. Blue dots are training data, red dots are test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Linear Regression Model\n",
    "\n",
    "Now we've got some data, let's build a model to use the **blue dots to predict the red dots**.\n",
    "\n",
    "![Linear Model](https://raw.githubusercontent.com/poridhiEng/lab-asset/7008e578e0c9c57813d1b267134700911793d762/tensorcode/Deep-learning-with-pytorch/LinearRegression/lab-01/images/linear-model.svg)\n",
    "\n",
    "We'll create a class that subclasses `nn.Module`. The model has two learnable parameters:\n",
    "- `self.weights`: Initialized with random values, multiplied with input X\n",
    "- `self.bias`: Initialized with random values, added to the result\n",
    "\n",
    "Both parameters use `nn.Parameter` with `requires_grad=True`, which tells PyTorch to track gradients so the values can be updated during training.\n",
    "\n",
    "The `forward()` method defines how data flows through the model — it computes `y = weights * x + bias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.randn(1, dtype=torch.float), requires_grad=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.weights * x + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Model Contents\n",
    "\n",
    "Let's create a model instance and check its parameters using `.parameters()` and `.state_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set manual seed since nn.Parameter are randomly initialized\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create an instance of the model\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "# Check the nn.Parameter(s) within the nn.Module subclass\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the state (what the model contains) using `.state_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List named parameters\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the values for `weights` and `bias` come out as **random float tensors**?\n",
    "\n",
    "This is because we initialized them using `torch.randn()`.\n",
    "\n",
    "We want to start from random parameters and get the model to update them towards the target values:\n",
    "- Target weight: **0.4**\n",
    "- Target bias: **0.1**\n",
    "\n",
    "Because our model starts with random values, right now it'll have **poor predictive power**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current model parameters:\")\n",
    "print(f\"  weights: {model_0.state_dict()['weights'].item():.4f}\")\n",
    "print(f\"  bias:    {model_0.state_dict()['bias'].item():.4f}\")\n",
    "\n",
    "print(f\"\\nTarget parameters:\")\n",
    "print(f\"  weight: {weight}\")\n",
    "print(f\"  bias:   {bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Predictions (Before Training)\n",
    "\n",
    "Let's see what predictions our untrained model makes. We use `torch.inference_mode()` as a context manager.\n",
    "\n",
    "`torch.inference_mode()` turns off gradient tracking and other training features to make forward-passes faster. It's used when making predictions (inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with model\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "# Note: in older PyTorch code you might see torch.no_grad()\n",
    "# with torch.no_grad():\n",
    "#   y_preds = model_0(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of testing samples: {len(X_test)}\")\n",
    "print(f\"Number of predictions made: {len(y_preds)}\")\n",
    "print(f\"Predicted values:\\n{y_preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how there's one prediction value per testing sample. For our straight line, one X value maps to one y value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Untrained Predictions\n",
    "\n",
    "Our predictions are still numbers on a page. Let's visualize them. We'll see some green dots, which are our model's predictions before training. There maybe some gaps between the green dots and the red dots, which are the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(predictions=y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Far Off Are We?\n",
    "\n",
    "Let's calculate the difference between predictions and actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test - y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Those predictions look pretty bad!**\n",
    "\n",
    "This makes sense though — our model is just using **random parameter values** to make predictions. It hasn't even looked at the blue dots to try to predict the red dots.\n",
    "\n",
    "Time to change that! In our next lab, we'll train the model to learn the correct parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, we:\n",
    "\n",
    "1. **Created synthetic data** with known parameters (weight=0.4, bias=0.1)\n",
    "2. **Split the data** into training (40 samples) and test sets (10 samples)\n",
    "3. **Visualized the data** as a straight line\n",
    "4. **Built a LinearRegressionModel** with random parameters\n",
    "5. **Made predictions** with the untrained model (they were bad!)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
