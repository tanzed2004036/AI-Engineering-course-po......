{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "# Lab 3: Save and Load Models\n",
        "\n",
        "In this notebook, we'll complete the final step of our PyTorch workflow — saving a trained model to disk and loading it back for future use. This is essential for deploying models or continuing work later."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {
        "id": "cell-1"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Run this cell to install the required libraries. We need PyTorch for model operations and `pathlib` (built-in) for file path handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cell-2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-2",
        "outputId": "b5a0abd2-f4c8-4507-8a54-295d15b4269b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {
        "id": "cell-3"
      },
      "source": [
        "## Setup from Labs 1 and 2\n",
        "\n",
        "Before we can save a model, we need a trained model. Let's quickly recreate everything from Labs 1 and 2.\n",
        "\n",
        "**From Lab 1 (Data and Model Building):**\n",
        "- Create synthetic data using `y = 0.4 * X + 0.1`\n",
        "- Split into 80% training and 20% testing sets\n",
        "- Define `LinearRegressionModel` class with learnable `weight` and `bias` parameters\n",
        "\n",
        "**From Lab 2 (Training Loop):**\n",
        "- Set up loss function (`nn.L1Loss`) and optimizer (`SGD` with lr=0.01)\n",
        "- Train for 100 epochs using the 5-step training loop\n",
        "- Model learns to approximate `weight ≈ 0.4` and `bias ≈ 0.1`\n",
        "\n",
        "![Linear Model](https://raw.githubusercontent.com/poridhiEng/lab-asset/7008e578e0c9c57813d1b267134700911793d762/tensorcode/Deep-learning-with-pytorch/LinearRegression/lab-02/images/linear-model.svg)\n",
        "\n",
        "The model takes input X, multiplies it by weights, adds bias, and outputs predictions. After training, it should discover `weight ≈ 0.4` and `bias ≈ 0.1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-4",
        "outputId": "4400f390-8e0d-452f-b657-a8408a6866e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 40, Test samples: 10\n",
            "Initial parameters: weight=0.3367, bias=0.1288\n",
            "Target parameters:  weight=0.4, bias=0.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Target parameters (what we want the model to learn)\n",
        "weight = 0.4\n",
        "bias = 0.1\n",
        "\n",
        "# Create data\n",
        "X = torch.arange(0, 1, 0.02).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "# Train/test split (80/20)\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "# Model definition\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "        self.bias = nn.Parameter(torch.randn(1), requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.weight * x + self.bias\n",
        "\n",
        "# Create model instance\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "print(f\"Initial parameters: weight={model.weight.item():.4f}, bias={model.bias.item():.4f}\")\n",
        "print(f\"Target parameters:  weight={weight}, bias={bias}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-5",
      "metadata": {
        "id": "cell-5"
      },
      "source": [
        "## Train the Model\n",
        "\n",
        "We'll quickly train the model using the 5-step training loop from Lab 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cell-6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-6",
        "outputId": "c839442f-2798-4d50-e09b-60f7c17ad396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0 | Loss: 0.0130\n",
            "Epoch  10 | Loss: 0.0095\n",
            "Epoch  20 | Loss: 0.0060\n",
            "Epoch  30 | Loss: 0.0026\n",
            "Epoch  40 | Loss: 0.0077\n",
            "Epoch  50 | Loss: 0.0077\n",
            "Epoch  60 | Loss: 0.0077\n",
            "Epoch  70 | Loss: 0.0077\n",
            "Epoch  80 | Loss: 0.0077\n",
            "Epoch  90 | Loss: 0.0077\n",
            "\n",
            "Training complete!\n",
            "Learned parameters: weight=0.3937, bias=0.0948\n",
            "Target parameters:  weight=0.4, bias=0.1\n"
          ]
        }
      ],
      "source": [
        "# Create loss function and optimizer\n",
        "loss_fn = nn.L1Loss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    # 1. Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 2. Forward pass\n",
        "    y_pred = model(X_train)\n",
        "\n",
        "    # 3. Calculate loss\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "    # 4. Backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch:3d} | Loss: {loss:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining complete!\")\n",
        "print(f\"Learned parameters: weight={model.weight.item():.4f}, bias={model.bias.item():.4f}\")\n",
        "print(f\"Target parameters:  weight={weight}, bias={bias}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {
        "id": "cell-7"
      },
      "source": [
        "## 1. Understanding state_dict()\n",
        "\n",
        "The `state_dict()` is a Python dictionary that maps each layer/parameter name to its tensor value. It contains all the learnable parameters of your model — in our case, just `weight` and `bias`.\n",
        "\n",
        "This is what we save to disk and load back later. By saving only the `state_dict()` (not the entire model), we keep our saved files small and portable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cell-8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-8",
        "outputId": "555f27ae-47bc-4b84-b791-444aa657028d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model state_dict():\n",
            "OrderedDict({'weight': tensor([0.3937]), 'bias': tensor([0.0948])})\n",
            "\n",
            "Breaking it down:\n",
            "  weight: 0.3937\n",
            "  bias: 0.0948\n"
          ]
        }
      ],
      "source": [
        "# View the state dict\n",
        "print(\"Model state_dict():\")\n",
        "print(model.state_dict())\n",
        "\n",
        "print(\"\\nBreaking it down:\")\n",
        "for param_name, param_value in model.state_dict().items():\n",
        "    print(f\"  {param_name}: {param_value.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-9",
      "metadata": {
        "id": "cell-9"
      },
      "source": [
        "## 2. Create a Models Directory\n",
        "\n",
        "It's good practice to organize saved models in a dedicated folder. This keeps your project clean and makes it easy to find model files later.\n",
        "\n",
        "We use Python's `pathlib.Path` for cross-platform compatibility — it handles file paths correctly on Windows, Mac, and Linux."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cell-10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-10",
        "outputId": "28d5d65d-e82c-45c1-b5b9-bc9497b6e969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model directory created: models\n"
          ]
        }
      ],
      "source": [
        "# Create models directory\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Model directory created: {MODEL_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-11",
      "metadata": {
        "id": "cell-11"
      },
      "source": [
        "## 3. Define the Save Path\n",
        "\n",
        "We use `.pth` or `.pt` extension for PyTorch model files. This is a convention (not required) that helps identify PyTorch models at a glance.\n",
        "\n",
        "Common naming patterns: `model_name.pth`, `model_v1.pt`, `best_model.pth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cell-12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-12",
        "outputId": "736500e3-a470-477a-b502-ed0bcb008cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model will be saved to: models/linear_regression_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Define model filename and full path\n",
        "MODEL_NAME = \"linear_regression_model.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\"Model will be saved to: {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-13",
      "metadata": {
        "id": "cell-13"
      },
      "source": [
        "## 4. Save the Model\n",
        "\n",
        "We save only the `state_dict()`, not the entire model object. This is the **recommended approach** because:\n",
        "\n",
        "- **Portable**: Works even if you rename classes or move files\n",
        "- **Flexible**: Can load into modified model architectures (if compatible)\n",
        "- **Smaller files**: Only stores the essential parameter values\n",
        "\n",
        "The alternative (`torch.save(model, path)`) saves the entire model but can break if your code structure changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cell-14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-14",
        "outputId": "e12b4087-2a37-4e2d-dd33-1bc93d2cb28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: models/linear_regression_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Save the model state dict\n",
        "torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)\n",
        "\n",
        "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-15",
      "metadata": {
        "id": "cell-15"
      },
      "source": [
        "## 5. Verify the File Exists\n",
        "\n",
        "Always verify that your model was saved successfully before moving on. A quick check now can save debugging time later.\n",
        "\n",
        "We'll confirm the file exists and list all files in the models directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "cell-16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-16",
        "outputId": "4c6cf040-dbbe-4762-a41d-974cde488eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: True\n",
            "Files in models: [PosixPath('models/linear_regression_model.pth')]\n"
          ]
        }
      ],
      "source": [
        "# Check if file exists\n",
        "print(f\"File exists: {MODEL_SAVE_PATH.exists()}\")\n",
        "\n",
        "# List files in models directory\n",
        "print(f\"Files in {MODEL_PATH}: {list(MODEL_PATH.iterdir())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-17",
      "metadata": {
        "id": "cell-17"
      },
      "source": [
        "## 6. Load the Model\n",
        "\n",
        "Loading a saved model involves three steps:\n",
        "\n",
        "1. **Create a new model instance** — This starts with random parameters (just like when we first built the model)\n",
        "2. **Load the saved state dict** — Use `torch.load()` to read the `.pth` file from disk\n",
        "3. **Apply to the model** — Use `load_state_dict()` to replace random parameters with trained ones\n",
        "\n",
        "**Important**: You must have access to the model class definition (`LinearRegressionModel`) to load the model. The saved file only contains parameter values, not the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cell-18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-18",
        "outputId": "5d2b1859-1905-4c69-b8c4-9bdb986586da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before loading (random params): OrderedDict({'weight': tensor([0.2345]), 'bias': tensor([0.2303])})\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a new model instance (with random parameters)\n",
        "loaded_model = LinearRegressionModel()\n",
        "print(f\"Before loading (random params): {loaded_model.state_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cell-19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-19",
        "outputId": "fe270173-fa98-467d-d35f-7324f6d1aefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After loading (trained params): OrderedDict({'weight': tensor([0.3937]), 'bias': tensor([0.0948])})\n"
          ]
        }
      ],
      "source": [
        "# Steps 2 & 3: Load the saved state dict into the model\n",
        "loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "print(f\"After loading (trained params): {loaded_model.state_dict()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-20",
      "metadata": {
        "id": "cell-20"
      },
      "source": [
        "Notice how the parameters changed from random values to the trained values after loading! The `load_state_dict()` function replaced all the random parameters with our saved trained parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-21",
      "metadata": {
        "id": "cell-21"
      },
      "source": [
        "## 7. Verify Predictions Match\n",
        "\n",
        "The ultimate test: the loaded model should produce **identical predictions** to the original trained model. If predictions match, we know the save/load process preserved all the learned parameters correctly.\n",
        "\n",
        "We use `torch.allclose()` to compare tensors — it returns `True` if all values are equal (within a small tolerance for floating-point precision)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cell-22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-22",
        "outputId": "14ab0d5c-063b-488e-8a85-bbbe36f92011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions match: True\n"
          ]
        }
      ],
      "source": [
        "# Original model predictions\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    original_preds = model(X_test)\n",
        "\n",
        "# Loaded model predictions\n",
        "loaded_model.eval()\n",
        "with torch.inference_mode():\n",
        "    loaded_preds = loaded_model(X_test)\n",
        "\n",
        "# Compare predictions\n",
        "predictions_match = torch.allclose(original_preds, loaded_preds)\n",
        "print(f\"Predictions match: {predictions_match}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cell-23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cell-23",
        "outputId": "87b84d45-9f25-4773-e8cc-548e8ad96d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model predictions (first 5):\n",
            "tensor([0.4097, 0.4176, 0.4255, 0.4334, 0.4412])\n",
            "\n",
            "Loaded model predictions (first 5):\n",
            "tensor([0.4097, 0.4176, 0.4255, 0.4334, 0.4412])\n",
            "\n",
            "Actual values (first 5):\n",
            "tensor([0.4200, 0.4280, 0.4360, 0.4440, 0.4520])\n"
          ]
        }
      ],
      "source": [
        "# Visual comparison\n",
        "print(\"Original model predictions (first 5):\")\n",
        "print(original_preds[:5].squeeze())\n",
        "\n",
        "print(\"\\nLoaded model predictions (first 5):\")\n",
        "print(loaded_preds[:5].squeeze())\n",
        "\n",
        "print(\"\\nActual values (first 5):\")\n",
        "print(y_test[:5].squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-24",
      "metadata": {
        "id": "cell-24"
      },
      "source": [
        "All predictions are identical! This confirms that our model was saved and loaded correctly. The loaded model behaves exactly like the original trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {
        "id": "cell-25"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this lab, we learned how to:\n",
        "\n",
        "1. **Understand `state_dict()`** — the dictionary containing all model parameters\n",
        "2. **Save a trained model** using `torch.save(model.state_dict(), path)`\n",
        "3. **Load a model** by creating a new instance and calling `load_state_dict(torch.load(path))`\n",
        "4. **Verify predictions match** using `torch.allclose()`\n",
        "\n",
        "## Complete PyTorch Workflow\n",
        "\n",
        "Congratulations! You've completed the full PyTorch workflow across three labs:\n",
        "\n",
        "1. **Lab 1: Data and Model Building** — Created data and built a model with random parameters\n",
        "2. **Lab 2: Training Loop** — Implemented the 5-step training loop to learn `weight ≈ 0.4` and `bias ≈ 0.1`\n",
        "3. **Lab 3: Save and Load** — Saved the trained model and loaded it back for future use\n",
        "\n",
        "These fundamentals apply to all PyTorch projects, whether you're building simple linear regression or complex deep learning models!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}